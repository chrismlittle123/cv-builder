{
  "profile": {
    "name": "Christopher Little",
    "title": "Data Consultant",
    "contact": {
      "phone": "07957610802", 
      "email": "chris@speedsheet.co.uk",
      "social": [
        {
          "platform": "github",
          "url": "https://github.com/chrismlittle123"
        }
      ]
    }
  },
  "education": [
    {
      "degreeName": "Mathematics",
      "type": "BACHELOR_OF_SCIENCE",
      "institution": "UNIVERSITY_OF_WARWICK", 
      "grade": "FIRST_CLASS_HONOURS",
      "startDate": "2014-09-01",
      "endDate": "2018-06-01"
    }
  ],
  "skills": [
    {
      "category": "PROGRAMMING_LANGUAGES",
      "items": [
        {
          "name": "Python",
          "proficiency": 5
        },
        {
          "name": "SQL",
          "proficiency": 4
        }
      ]
    },
    {
      "category": "DATA_TOOLS",
      "items": [
        {
          "name": "Apache Airflow",
          "proficiency": 5
        },
        {
          "name": "DBT",
          "proficiency": 5
        },
        {
          "name": "Apache Spark",
          "proficiency": 4
        }
      ]
    },
    {
      "category": "CLOUD_TECHNOLOGIES",
      "items": [
        {
          "name": "AWS Lambda",
          "proficiency": 5
        },
        {
          "name": "AWS DynamoDB",
          "proficiency": 4
        },
        {
          "name": "Terraform",
          "proficiency": 4
        }
      ]
    },
    {
      "category": "CONTAINERIZATION",
      "items": [
        {
          "name": "Docker",
          "proficiency": 4
        },
        {
          "name": "Kubernetes",
          "proficiency": 3
        }
      ]
    },
    {
      "category": "DATABASE_SYSTEMS",
      "items": [
        {
          "name": "Snowflake",
          "proficiency": 5
        },
        {
          "name": "PostgreSQL",
          "proficiency": 5
        },
        {
          "name": "MySQL",
          "proficiency": 5
        }
      ]
    },
    {
      "category": "VISUALIZATION",
      "items": [
        {
          "name": "Streamlit",
          "proficiency": 5
        },
        {
          "name": "Looker",
          "proficiency": 4
        },
        {
          "name": "Power BI",
          "proficiency": 4
        },
        {
          "name": "Tableau",
          "proficiency": 4
        }
      ]
    },
    {
      "category": "DEVOPS",
      "items": [
        {
          "name": "GitHub Actions",
          "proficiency": 4
        }
      ]
    }
  ],
  "experience": [
    {
      "startDate": "2024-02-01",
      "endDate": null,
      "company": "SpeedSheet",
      "locationCity": "Oxford",
      "locationCountry": "UK",
      "title": "Co-Founder and Chief Technology Officer",
      "description": "Who we are: At SpeedSheet, our aim is to make automating Excel processes fast and simple. We help businesses upgrade their Excel workflows and work on a project by project basis. Our secret sauce is a software tool that automatically turns Excel spreadsheets into a super fast data pipeline and/or web application.",
      "achievements": []
    },
    {
      "startDate": "2023-09-01",
      "endDate": "2024-02-01",
      "company": "ICS Consulting",
      "locationCity": "Warwick",
      "locationCountry": "UK",
      "title": "Senior Data Consultant - Engineering Forecasting Models",
      "description": null,
      "achievements": [
        "Excel Migration: Migrated a large and complex Excel process. The existing process generated over 100 infrastructure asset forecasting reports for Ofgem using Excel and VBA. I migrated this process to use a MySQL database and a pipeline powered by Apache Airflow, Python and SQL. The project saved approximately 100 FTE hours per month.",
        "Data Cleaning Automation: Developed an internal software tool that extracts and cleans highly unstructured data from Excel spreadsheets using AI. Implemented the tool to save approximately 20 FTE hours per month for the business."
      ]
    },
    {
      "startDate": "2022-09-01",
      "endDate": "2023-09-01", 
      "company": "Sonnedix",
      "locationCity": "London",
      "locationCountry": "UK",
      "title": "Data Engineer - AI Implementation Team",
      "description": null,
      "achievements": [
        "Financial Analysis Web Application: Developed a large-scale application using Typescript and React. This application integrated weather data, energy prices, and site-specific data to calculate expected solar site revenues. Backend was constructed using NestJS, using the Jest testing framework and containerised using Docker, with deployment managed through Kubernetes.",
        "Data Pipelining: Utilised Apache Spark within Palantir Foundry to build and maintain data pipelines, ensuring scalability and performance. Developed both cross-sectional and time series datasets from weather and operational data providers.",
        "Real-time Dashboards: Implemented Apache Kafka for data streaming, integrating with Foundry to build a real-time Operational Statistics dashboard.",
        "Machine Learning: Led a project that forecasted long-term irradiation trends across solar sites in Japan, achieving a 0.4% annual increase in revenue forecasts. Additionally, built a solar panel detection model using YoloV5 image recognition which was integrated into a Solar Site Prospecting tool."
      ]
    },
    {
      "startDate": "2019-06-01",
      "endDate": "2022-09-01",
      "company": "Cazoo",
      "locationCity": "London",
      "locationCountry": "UK",
      "title": "Data Engineer - Purchasing Team",
      "description": null,
      "achievements": [
        "Data Management: Managed data primarily from Autotrader and Cazana. Automated the calculation of car prices, overcoming challenges with configuration files. Developed a Streamlit app for configuration management, allowing users to make updates without breaking the application.",
        "Backend Development: Transitioned from Google Sheets to a more efficient backend system for the Purchasing process, achieving significant speed improvements, using AWS Lambda, DynamoDB, Docker, and AppSync. Implemented a MySQL database connected to a Google Sheet via Google AppScript, serving as a real-time lookup table for the Purchasing team.",
        "Data Modeling: Modeled data into Redshift using SQL and DBT. Utilised Looker for data visualisation."
      ]
    }
  ]
}
